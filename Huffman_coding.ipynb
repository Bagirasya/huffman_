{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "import heapq\n",
    "import gevent\n",
    "from multiprocessing import Pool \n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(namedtuple('Node', ['left', 'right'])):\n",
    "    def walk(self, code, symcode):\n",
    "        self.left.walk(code, symcode + \"0\")\n",
    "        self.right.walk(code, symcode + \"1\")\n",
    "        \n",
    "class Leaf(namedtuple('Leaf', ['char'])):\n",
    "    def walk(self, code, symcode):\n",
    "        if symcode:\n",
    "            code[self.char] = symcode\n",
    "        else:\n",
    "            code[self.char] = \"0\"\n",
    "\n",
    "def crt_heap(s):    \n",
    "    h=[]\n",
    "    for sym, pr in Counter(s).items():\n",
    "        h.append((pr, len(h), Leaf(sym)))\n",
    "    return h\n",
    "        \n",
    "def huffman_enc(h):\n",
    "    count = len(h)\n",
    "    while len(h) > 1:\n",
    "        pr1, count1, left = heapq.heappop(h)\n",
    "        pr2, count2, right = heapq.heappop(h)\n",
    "        heapq.heappush(h, (pr1 + pr2, count, Node(left, right)))\n",
    "        count += 1\n",
    "    coding = {}\n",
    "    if h:\n",
    "        [(_pr, _count, root)] = h\n",
    "        root.walk(coding, \"\")\n",
    "    return coding\n",
    "\n",
    "def huffman_out(h, codec):\n",
    "    out = ''\n",
    "    for i in h:\n",
    "        out = out + codec[i]\n",
    "    return out\n",
    "    \n",
    "\n",
    "# create bunch of gibberish filled files\n",
    "def create_rand_fls(workpath : str, count_f : int):\n",
    "    for i in range(count_f):\n",
    "        newfile = 'rand'+str(i) + '.txt'\n",
    "        file = open(os.path.join(workpath, newfile), \"w\")\n",
    "        gib = ''.join(random.choices(string.ascii_letters + string.digits, k= random.randint(1, 25)))\n",
    "        file.write(gib) \n",
    "        file.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm for a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many text files need to be created?\n",
      "2\n",
      "Specify working directory\n",
      "C:\\\\Users\\\\Ася\\\\huffman files txt\n",
      "['rand0.txt', 'rand1.txt']\n"
     ]
    }
   ],
   "source": [
    "count_f = None\n",
    "while count_f is None:\n",
    "    try:\n",
    "        count_f = int(input('How many text files need to be created?\\n'))\n",
    "    except ValueError:\n",
    "        print('This is not a number. Enter a value that can be converted to a numeric\\n')\n",
    "        \n",
    "#working_path = 'C:\\\\Users\\\\Ася\\\\huffman files txt'\n",
    "working_path = input('Specify working directory\\n')\n",
    "if os.path.exists(working_path) and not os.path.isfile(working_path):\n",
    "    pass\n",
    "else:\n",
    "    print('The specified directory does not exist')\n",
    "\n",
    "    \n",
    "create_rand_fls(working_path, count_f)\n",
    "file_names = os.listdir(working_path)\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(workpath):\n",
    "    for every in os.listdir(workpath):\n",
    "        curfile = open(os.path.join(workpath, every), \"r\")\n",
    "        s = curfile.readline()\n",
    "        curfile.close()\n",
    "        new_heap = crt_heap(s)\n",
    "        heapq.heapify(new_heap)\n",
    "        coding111 = huffman_enc(new_heap)\n",
    "        output = huffman_out(s, coding111)\n",
    "        print('Content of file', every, ':', s, '\\n', coding111, '\\n', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of file rand0.txt : hT09wWDCYaAA7poOcNiP80 \n",
      " {'a': '0000', '7': '0001', 'p': '0010', 'o': '0011', 'O': '0100', 'c': '0101', 'N': '0110', 'i': '0111', 'P': '1000', '8': '1001', '0': '1010', 'A': '1011', 'h': '11000', 'T': '11001', '9': '11010', 'w': '11011', 'W': '11100', 'D': '11101', 'C': '11110', 'Y': '11111'} \n",
      " 110001100110101101011011111001110111110111110000101110110001001000110100010101100111100010011010\n",
      "Content of file rand1.txt : 8CPYA97WWo2xTHEJgj \n",
      " {'P': '0000', 'Y': '0001', 'A': '0010', '9': '0011', '7': '0100', 'o': '0101', '2': '0110', 'x': '0111', 'T': '1000', 'H': '1001', 'E': '1010', 'J': '1011', 'g': '1100', 'j': '1101', 'W': '1110', '8': '11110', 'C': '11111'} \n",
      " 11110111110000000100100011010011101110010101100111100010011010101111001101\n",
      "Wall time: 223 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    with Pool(2) as p:\n",
    "        main(working_path) #сюда добавить map по элементам в директории file_names вместо цикла из main. Возможно, так мультипроц-ть будет быстрее\n",
    "        #map(main, file_names)\n",
    "    for f in os.listdir(working_path):\n",
    "        os.remove(os.path.join(working_path, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm for several string sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание отдельных справочников не совсем соответствует заданию. Нужно конкатенировать все данные в одну строку и работать с ней - создать алгоритм Хаффмана. Далее print('Content of file', every.name, ':', s, '\\n', coding111, '\\n', output) для каждого файла с общим словарем. Я это буду реализовывать в другом main тут же ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
